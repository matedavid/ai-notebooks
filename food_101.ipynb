{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNklys7l96UT"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWakD_Z7wJZx",
    "outputId": "437b49ce-613a-4336-a055-c5864232bdb0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPJmM9QzLUYO",
    "outputId": "b61a07f1-b9b9-4d58-ced8-cab72af4f9a9"
   },
   "outputs": [],
   "source": [
    "images_path = Path(\"/content/drive/MyDrive/Projects/Food-101/food_101_data/images\")\n",
    "food_names = os.listdir(images_path)\n",
    "len(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWZ6mtSe_Fcy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0-Z6k1jjYAO"
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "  def __init__(self, food_names):\n",
    "    self.X = []\n",
    "    self.Y = []\n",
    "\n",
    "    self.preprocess = transforms.Compose([\n",
    "      transforms.Resize(224),\n",
    "      transforms.CenterCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    number_foods = len(food_names)\n",
    "    food2idx = { name:idx for idx, name in enumerate(food_names) }\n",
    "\n",
    "    IMG_SIZE = 128\n",
    "    for idx, food_name in enumerate(food_names):\n",
    "      food_path = images_path/food_name\n",
    "      food_idx = food2idx[food_name]\n",
    "      \n",
    "      print(f\"Preparing {food_name}: {idx+1}/{number_foods}\")\n",
    "\n",
    "      for img_name in tqdm(os.listdir(food_path)):\n",
    "        image_path = food_path/img_name\n",
    "        \n",
    "        img = Image.open(str(image_path))\n",
    "\n",
    "        try:\n",
    "          img = self.preprocess(img)\n",
    "          \n",
    "          self.X.append(img)\n",
    "          self.Y.append(food_idx)\n",
    "        except: \n",
    "          pass\n",
    "\n",
    "    self.Y = np.array(self.Y)\n",
    "  \n",
    "  def one_hot_encode(self, idx, length):\n",
    "    onehot = np.zeros((length, 1))\n",
    "    onehot[idx] = 1\n",
    "    return onehot\n",
    "\n",
    "  def __len__(self):\n",
    "    assert len(self.X) == len(self.Y)\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwmVCZRsFgI0"
   },
   "outputs": [],
   "source": [
    "test_food_names = [\n",
    "  \"chicken_wings\",\n",
    "  \"churros\",\n",
    "  \"donuts\",\n",
    "  \"french_fries\",\n",
    "  \"hamburger\",\n",
    "  \"hot_dog\",\n",
    "  \"ice_cream\",\n",
    "  \"lasagna\",\n",
    "  \"cheesecake\",\n",
    "  \"apple_pie\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vK_sm5gboAa4",
    "outputId": "f24d5936-d82f-4257-a5f3-87137fe913f7"
   },
   "outputs": [],
   "source": [
    "food_dataset = FoodDataset(test_food_names)\n",
    "len(food_dataset), food_dataset[0][0].shape, food_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKeYAINdWEmO"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(images_path/\"../test_food_dataset\", \"wb\") as f:\n",
    "  pickle.dump(food_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKIn09ou2kE4",
    "outputId": "7ae9aeb9-199c-4396-bb87-1381b7b83cae"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(images_path/\"../test_food_dataset\", \"rb\") as f:\n",
    "  food_dataset = pickle.load(f)\n",
    "len(food_dataset), food_dataset[0][0].shape, food_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fonUDSnso4k",
    "outputId": "371856ba-9e7e-4233-9fb3-2d8378ff7e39"
   },
   "outputs": [],
   "source": [
    "dataset = DataLoader(food_dataset, batch_size=64, shuffle=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKQidzJn3cUO"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5-8A9m2zK-R"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "  since = time.time()\n",
    "  best_acc = 0.0\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}/{num_epochs-1}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    n_epoch = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # Iterate over data\n",
    "    for inputs, labels in dataloader:\n",
    "      inputs = inputs.to(device).float()\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Zero the parameters of the gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      n_epoch += inputs.size()[0]\n",
    "\n",
    "      # Forward Propagation\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Backward Propagation + Optimize \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item() * inputs.size(0)\n",
    "      running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / n_epoch\n",
    "    epoch_acc = running_corrects.double() / n_epoch\n",
    "\n",
    "    print(\"Loss: {:.4f} Acc: {:.4f}\".format(epoch_loss, epoch_acc))\n",
    "\n",
    "  time_elapsed = time.time() - since\n",
    "  print(f\"Training complete in {time_elapsed // 60}m {time_elapsed % 60}\")\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su0uNOhj5Ma_"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8mXF2n74mZ0"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    " \n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu-8NUBU5Nu7",
    "outputId": "7a67a0ee-523c-461b-9fd0-f1be312c7fac"
   },
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, dataset, criterion, optimizer_ft, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5DTn_113Zk8"
   },
   "source": [
    "## Own training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaBZXIXeuDT2"
   },
   "outputs": [],
   "source": [
    "class Foodnet(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(Foodnet, self).__init__()\n",
    "    \n",
    "    # Vgg19\n",
    "    self.conv1 = nn.Sequential(\n",
    "      nn.Conv2d(3, 64, (3,3), padding=1),\n",
    "      nn.Conv2d(64, 64, (3,3), padding=1)\n",
    "    )\n",
    "    self.maxpool1 = nn.MaxPool2d((2,2), stride=2)\n",
    "\n",
    "    self.conv2 = nn.Sequential(\n",
    "      nn.Conv2d(64, 128, (3,3), padding=1),\n",
    "      nn.Conv2d(128, 128, (3,3), padding=1)    \n",
    "    )\n",
    "    self.maxpool2 = nn.MaxPool2d((2,2), stride=2)\n",
    "\n",
    "    self.conv3 = nn.Sequential(\n",
    "      nn.Conv2d(128, 256, (3,3), padding=1),\n",
    "      nn.Conv2d(256, 256, (3,3), padding=1),\n",
    "      nn.Conv2d(256, 256, (3,3), padding=1),\n",
    "      nn.Conv2d(256, 256, (3,3), padding=1)\n",
    "    )\n",
    "    self.maxpool3 = nn.MaxPool2d((2,2), stride=2)\n",
    "  \n",
    "    self.conv4 = nn.Sequential(\n",
    "      nn.Conv2d(256, 512, (3,3), padding=1),\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1),\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1),\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1)\n",
    "    )\n",
    "    self.maxpool4 = nn.MaxPool2d((2,2), stride=2)\n",
    "\n",
    "    self.conv5 = nn.Sequential(\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1),\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1),\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1),\n",
    "      nn.Conv2d(512, 512, (3,3), padding=1)\n",
    "    )\n",
    "    self.maxpool5 = nn.MaxPool2d((2,2), stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(25088, 4096)\n",
    "    self.fc2 = nn.Linear(4096, 4096)\n",
    "    self.fc3 = nn.Linear(4096, n_classes)\n",
    "\n",
    "  def forward(self, X):\n",
    "    X = self.conv1(X)\n",
    "    X = self.maxpool1(X)\n",
    "\n",
    "    X = self.conv2(X)\n",
    "    X = self.maxpool2(X)\n",
    "    \n",
    "    X = self.conv3(X)\n",
    "    X = self.maxpool3(X)\n",
    "\n",
    "    X = self.conv4(X)\n",
    "    X = self.maxpool4(X)\n",
    "\n",
    "    X = self.conv5(X)\n",
    "    X = self.maxpool5(X)\n",
    "\n",
    "    X = torch.flatten(X, 1)\n",
    "\n",
    "    X = self.fc1(X)\n",
    "    X = self.fc2(X)\n",
    "    X = self.fc3(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDrhFVoe2YJy"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)\n",
    "\n",
    "net = Foodnet(len(test_food_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "opt = optim.Adam(net.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "0952UWrl76cg",
    "outputId": "dd158278-5cac-4732-f8c2-68c800eb04ff"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  epoch_loss = 0.\n",
    "  epoch_acc = 0\n",
    "  n_epoch = 0\n",
    "\n",
    "  for x_batch, y_batch in dataset:\n",
    "    x_batch = x_batch.to(device).float()\n",
    "    y_batch = y_batch.to(device).long()\n",
    "\n",
    "    out = net(x_batch)\n",
    "\n",
    "    if y_batch.size()[0] != 64:\n",
    "      continue\n",
    "\n",
    "    net.zero_grad()\n",
    "    loss = criterion(out, y_batch)\n",
    "    \n",
    "    loss.backward()20\n",
    "    opt.step()\n",
    "\n",
    "    batch_acc = out.argmax(dim=1)\n",
    "    epoch_acc += (batch_acc == y_batch).sum().float()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    n_epoch += x_batch.size()[0]\n",
    "\n",
    "  epoch_loss /= n_epoch\n",
    "  epoch_acc /= n_epoch\n",
    "  print(f\"EPOCH: {epoch+1}/{EPOCHS} - loss: {epoch_loss} - acc: {epoch_acc*100}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vqJ7RFM_I0Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eKQidzJn3cUO"
   ],
   "name": "food-101.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
